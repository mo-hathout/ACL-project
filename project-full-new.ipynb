{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6727279,"sourceType":"datasetVersion","datasetId":3475962},{"sourceId":13437321,"sourceType":"datasetVersion","datasetId":8529020}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# AIRLINE CUSTOMER SATISFACTION - MILESTONE 1\n# German University in Cairo - CSEN 903\n# ============================================================================\n\n# ============================================================================\n# INSTALL REQUIRED PACKAGES\n# ============================================================================\n\nimport sys\nimport subprocess\n\ndef install_package(package):\n    \"\"\"Install package if not already installed\"\"\"\n    try:\n        if package == 'vaderSentiment':\n            __import__('vaderSentiment')\n        else:\n            __import__(package)\n        print(f\"‚úì {package} already installed\")\n    except ImportError:\n        print(f\"Installing {package}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n        print(f\"‚úì {package} installed successfully\")\n\nprint(\"Checking and installing required packages...\")\nprint(\"=\"*70)\ninstall_package('vaderSentiment')\ninstall_package('shap')\ninstall_package('lime')\nprint(\"=\"*70)\nprint(\"‚úì All required packages ready!\\n\")\n\n# ============================================================================\n# PART 1: SETUP & DATA LOADING\n# ============================================================================\n\nprint(\"=\"*70)\nprint(\"IMPORTING LIBRARIES\")\nprint(\"=\"*70)\n\n# Core data processing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"‚úì Core libraries imported\")\n\n# For sentiment analysis\ntry:\n    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n    print(\"‚úì VADER Sentiment Analysis imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Error importing VADER: {e}\")\n    print(\"   Please restart kernel and run again\")\n\n# For ML models\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                             f1_score, confusion_matrix, classification_report, \n                             roc_curve, auc)\nprint(\"‚úì Scikit-learn libraries imported\")\n\n# For Neural Networks\ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Dropout\n    from tensorflow.keras.callbacks import EarlyStopping\n    print(f\"‚úì TensorFlow {tf.__version__} imported\")\nexcept ImportError:\n    print(\"‚ö† TensorFlow not available - Neural Network will be skipped\")\n\n# For XAI (Explainable AI)\ntry:\n    import shap\n    print(\"‚úì SHAP imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Error importing SHAP: {e}\")\n\ntry:\n    from lime import lime_tabular\n    print(\"‚úì LIME imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Error importing LIME: {e}\")\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nprint(\"‚úì Visualization settings configured\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ALL LIBRARIES IMPORTED SUCCESSFULLY!\")\nprint(\"=\"*70)\n\n# Display versions\nprint(\"\\nLibrary Versions:\")\nprint(f\"  Python: {sys.version.split()[0]}\")\nprint(f\"  Pandas: {pd.__version__}\")\nprint(f\"  NumPy: {np.__version__}\")\nimport matplotlib\nprint(f\"  Matplotlib: {matplotlib.__version__}\")\nprint(f\"  Seaborn: {sns.__version__}\")\nimport sklearn\nprint(f\"  Scikit-learn: {sklearn.__version__}\")\ntry:\n    print(f\"  TensorFlow: {tf.__version__}\")\nexcept:\n    print(f\"  TensorFlow: Not available\")\ntry:\n    print(f\"  SHAP: {shap.__version__}\")\nexcept:\n    print(f\"  SHAP: Version not available\")\n\n# Quick VADER test\nprint(\"\\n\" + \"=\"*70)\nprint(\"TESTING VADER SENTIMENT ANALYZER\")\nprint(\"=\"*70)\ntry:\n    analyzer = SentimentIntensityAnalyzer()\n    test_text = \"This is an excellent flight with great service!\"\n    test_score = analyzer.polarity_scores(test_text)\n    print(f\"Test text: '{test_text}'\")\n    print(f\"Sentiment scores: {test_score}\")\n    print(\"‚úì VADER is working correctly!\")\nexcept Exception as e:\n    print(f\"‚ùå VADER test failed: {e}\")\n    print(\"   Please restart kernel and try again\")\n\n# ============================================================================\n# LOAD DATASETS\n# ============================================================================\n\n\"\"\"\nWe have 4 CSV files:\n1. AirlineScrappedReview.csv (use cleaned version from CMS)\n2. Customer_comment.csv\n3. Passanger_booking_data.csv\n4. Survey_data_Inflight_Satisfaction_Score.csv\n\"\"\"\n\n# Import kagglehub\ntry:\n    import kagglehub\n    from kagglehub import KaggleDatasetAdapter\n    print(\"‚úì KaggleHub imported\")\n    use_kagglehub = True\nexcept ImportError:\n    print(\"Installing kagglehub...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kagglehub\", \"-q\"])\n    import kagglehub\n    from kagglehub import KaggleDatasetAdapter\n    print(\"‚úì KaggleHub installed and imported\")\n    use_kagglehub = True\n\n# Initialize dataset variables\ndf_reviews = None\ndf_comments = None\ndf_booking = None\ndf_survey = None\n\n# Load each dataset\nprint(\"\\n\" + \"=\"*70)\nprint(\"LOADING DATASETS\")\nprint(\"=\"*70)\n\n# Method 1: Try kagglehub\nif use_kagglehub:\n    try:\n        # Dataset 1: Airline Scrapped Review\n        print(\"\\nLoading AirlineScrappedReview.csv...\")\n        df_reviews = kagglehub.load_dataset(\n            KaggleDatasetAdapter.PANDAS,\n            \"/kaggle/input/cleanedcms/AirlineScrappedReview_Cleaned.csv\"\n        )\n        print(f\"‚úì Loaded AirlineScrappedReview.csv: {df_reviews.shape}\")\n\n        # Dataset 2: Customer Comments\n        print(\"\\nLoading Customer_comment.csv...\")\n        df_comments = kagglehub.load_dataset(\n            KaggleDatasetAdapter.PANDAS,\n            \"manishkumar7432698/airline-passangers-booking-data\",\n            \"Customer_comment.csv\"\n        )\n        print(f\"‚úì Loaded Customer_comment.csv: {df_comments.shape}\")\n\n        # Dataset 3: Passenger Booking Data\n        print(\"\\nLoading Passanger_booking_data.csv...\")\n        df_booking = kagglehub.load_dataset(\n            KaggleDatasetAdapter.PANDAS,\n            \"manishkumar7432698/airline-passangers-booking-data\",\n            \"Passanger_booking_data.csv\"\n        )\n        print(f\"‚úì Loaded Passanger_booking_data.csv: {df_booking.shape}\")\n\n        # Dataset 4: Survey Data - Inflight Satisfaction\n        print(\"\\nLoading Survey_data_Inflight_Satisfaction_Score.csv...\")\n        df_survey = kagglehub.load_dataset(\n            KaggleDatasetAdapter.PANDAS,\n            \"manishkumar7432698/airline-passangers-booking-data\",\n            \"Survey_data_Inflight_Satisfaction_Score.csv\"\n        )\n        print(f\"‚úì Loaded Survey_data_Inflight_Satisfaction_Score.csv: {df_survey.shape}\")\n        \n        use_kagglehub = True  # Success!\n\n    except Exception as e:\n        print(f\"\\n‚ö† KaggleHub loading failed: {e}\")\n        print(\"Trying alternative method...\")\n        use_kagglehub = False\n\n# Method 2: Direct file paths (fallback)\nif not use_kagglehub or df_reviews is None:\n    print(\"\\nUsing direct file path method...\")\n    try:\n        base_path = '/kaggle/input/airline-passangers-booking-data/'\n        \n        df_reviews = pd.read_csv(base_path + 'AirlineScrappedReview.csv')\n        print(f\"‚úì Loaded AirlineScrappedReview.csv: {df_reviews.shape}\")\n        \n        df_comments = pd.read_csv(base_path + 'Customer_comment.csv')\n        print(f\"‚úì Loaded Customer_comment.csv: {df_comments.shape}\")\n        \n        df_booking = pd.read_csv(base_path + 'Passanger_booking_data.csv')\n        print(f\"‚úì Loaded Passanger_booking_data.csv: {df_booking.shape}\")\n        \n        df_survey = pd.read_csv(base_path + 'Survey_data_Inflight_Satisfaction_Score.csv')\n        print(f\"‚úì Loaded Survey_data_Inflight_Satisfaction_Score.csv: {df_survey.shape}\")\n        \n    except FileNotFoundError as e:\n        print(f\"‚ùå File not found: {e}\")\n        print(\"\\nüìå IMPORTANT: Please add the dataset to your Kaggle notebook:\")\n        print(\"   1. Click '+ Add Data' in the right panel\")\n        print(\"   2. Search for 'airline-passangers-booking-data'\")\n        print(\"   3. Add the dataset by manishkumar7432698\")\n        print(\"   4. Rerun this cell\")\n    except Exception as e:\n        print(f\"‚ùå Error loading files: {e}\")\n\n# Verify all datasets loaded\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATASET LOADING VERIFICATION\")\nprint(\"=\"*70)\n\ndatasets_loaded = {\n    'AirlineScrappedReview': df_reviews is not None,\n    'Customer_comment': df_comments is not None,\n    'Passanger_booking_data': df_booking is not None,\n    'Survey_data_Inflight_Satisfaction': df_survey is not None\n}\n\nall_loaded = all(datasets_loaded.values())\n\nfor name, loaded in datasets_loaded.items():\n    status = \"‚úì\" if loaded else \"‚ùå\"\n    print(f\"{status} {name}: {'Loaded' if loaded else 'NOT LOADED'}\")\n\nif all_loaded:\n    print(\"\\n‚úÖ All datasets loaded successfully!\")\nelse:\n    print(\"\\n‚ö† WARNING: Some datasets failed to load!\")\n    print(\"   Please check the error messages above and fix the issue.\")\n    print(\"   The notebook may not work correctly without all datasets.\")\n\nprint(\"=\"*70)\n\n# ============================================================================\n# INITIAL DATA EXPLORATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"INITIAL DATA EXPLORATION\")\nprint(\"=\"*70)\n\n# Function to explore dataset\ndef explore_dataset(df, name):\n    \"\"\"Explore and display information about a dataset\"\"\"\n    if df is None:\n        print(f\"\\n‚ö† {name}: Dataset not loaded - skipping exploration\")\n        return\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"Dataset: {name}\")\n    print(f\"{'='*70}\")\n    print(f\"Shape: {df.shape} (rows: {df.shape[0]:,}, columns: {df.shape[1]})\")\n    \n    print(f\"\\nColumn Names and Types:\")\n    print(df.dtypes)\n    \n    print(f\"\\nFirst 3 rows:\")\n    print(df.head(3))\n    \n    print(f\"\\nMissing Values:\")\n    missing = df.isnull().sum()\n    if missing.sum() > 0:\n        print(missing[missing > 0])\n    else:\n        print(\"No missing values!\")\n    \n    print(f\"\\nDuplicate Rows: {df.duplicated().sum()}\")\n    \n    print(f\"\\nBasic Statistics (numerical columns):\")\n    if len(df.select_dtypes(include=[np.number]).columns) > 0:\n        print(df.describe())\n    else:\n        print(\"No numerical columns found\")\n\n# Explore each dataset (only if loaded)\nif df_reviews is not None:\n    explore_dataset(df_reviews, \"AirlineScrappedReview\")\nelse:\n    print(\"\\n‚ö† AirlineScrappedReview not loaded - cannot explore\")\n\nif df_comments is not None:\n    explore_dataset(df_comments, \"Customer_comment\")\nelse:\n    print(\"\\n‚ö† Customer_comment not loaded - cannot explore\")\n\nif df_booking is not None:\n    explore_dataset(df_booking, \"Passanger_booking_data\")\nelse:\n    print(\"\\n‚ö† Passanger_booking_data not loaded - cannot explore\")\n\nif df_survey is not None:\n    explore_dataset(df_survey, \"Survey_data_Inflight_Satisfaction\")\nelse:\n    print(\"\\n‚ö† Survey_data_Inflight_Satisfaction not loaded - cannot explore\")\n\n# Final status\nprint(\"\\n\" + \"=\"*70)\nif all_loaded:\n    print(\"‚úì Initial data exploration complete!\")\nelse:\n    print(\"‚ö† Data exploration complete (with some datasets missing)\")\n    print(\"  Please fix loading errors before proceeding to next parts\")\nprint(\"=\"*70)\n\n\n\n\n\n# Robust loader for the survey CSV (replace the previous loading-cell)\nimport os\nimport pandas as pd\n\ndef find_csv_candidates(root=\"/kaggle/input\", keywords=None):\n    \"\"\"Return list of CSV file paths under `root` that contain any of the keywords (case-insensitive).\"\"\"\n    if keywords is None:\n        keywords = [\"survey\", \"satisfaction\", \"inflight\", \"survey_data\"]\n    candidates = []\n    for dirpath, dirnames, filenames in os.walk(root):\n        for f in filenames:\n            if f.lower().endswith('.csv'):\n                path = os.path.join(dirpath, f)\n                # include if any keyword in filename\n                low = f.lower()\n                if any(k.lower() in low for k in keywords):\n                    candidates.append(path)\n    return sorted(set(candidates))\n\ndef list_all_csvs(root=\"/kaggle/input\"):\n    files = []\n    for dirpath, dirnames, filenames in os.walk(root):\n        for f in filenames:\n            if f.lower().endswith('.csv'):\n                files.append(os.path.join(dirpath, f))\n    return sorted(files)\n\ndef try_read_csv(path):\n    \"\"\"Try reading a CSV with safe fallbacks for encoding/engine.\"\"\"\n    try:\n        df = pd.read_csv(path)\n        return df, None\n    except Exception as e:\n        # try other common encodings & engine\n        for enc in ['utf-8', 'latin1', 'cp1252']:\n            try:\n                df = pd.read_csv(path, encoding=enc)\n                return df, None\n            except Exception:\n                continue\n        # try python engine with error replacement\n        try:\n            df = pd.read_csv(path, engine='python', encoding='utf-8', error_bad_lines=False, warn_bad_lines=True)\n            return df, None\n        except Exception as e2:\n            return None, (e, e2)\n\n# 1) Show all CSVs found under /kaggle/input (helpful for debugging paths)\nprint(\"Listing CSV files under /kaggle/input (first 200 shown):\")\nall_csvs = list_all_csvs(\"/kaggle/input\")\nfor i, p in enumerate(all_csvs[:200], 1):\n    print(f\"{i:03d}. {p}\")\nif not all_csvs:\n    print(\">> No CSV files found under /kaggle/input. Make sure you added the dataset to the notebook (Use '+ Add data').\")\n\n# 2) Find candidate survey CSVs by keywords\ncandidates = find_csv_candidates(\"/kaggle/input\", keywords=[\"survey\", \"satisfaction\", \"inflight\", \"survey_data\", \"Survey\"])\nprint(\"\\nCandidate survey CSVs (by filename keywords):\")\nif candidates:\n    for i, p in enumerate(candidates, 1):\n        print(f\"{i:03d}. {p}\")\nelse:\n    print(\">> No candidates matched keywords. You can still check the full listing above.\")\n\n# 3) If exactly one candidate, try to load it; if multiple, try each and pick the one that looks like a survey\ndf_survey = None\nif candidates:\n    for path in candidates:\n        print(f\"\\nTrying to load: {path}\")\n        df_try, errs = try_read_csv(path)\n        if df_try is not None:\n            # quick heuristic: require at least 2 columns and >0 rows\n            if df_try.shape[1] >= 2 and df_try.shape[0] > 0:\n                df_survey = df_try\n                print(f\"‚úì Loaded survey candidate: {path} -> shape {df_survey.shape}\")\n                break\n            else:\n                print(f\"  Loaded but shape looks small: {df_try.shape} ‚Äî continuing to next candidate\")\n        else:\n            print(f\"  Failed to read {path}. Errors: {errs}\")\nelse:\n    # fallback: ask user to choose from all CSVs (if any)\n    if all_csvs:\n        print(\"\\nNo keyword-matching candidates found. Trying the first CSV in the dataset as a last resort.\")\n        fallback = all_csvs[0]\n        df_try, errs = try_read_csv(fallback)\n        if df_try is not None:\n            df_survey = df_try\n            print(f\"‚úì Loaded fallback CSV: {fallback} -> shape {df_survey.shape}\")\n        else:\n            print(f\"‚ùå Failed to read fallback CSV: {fallback}. Errors: {errs}\")\n\n# 4) Final check & exploration\nif df_survey is None:\n    print(\"\\n‚ùå Could not load any survey CSV automatically.\")\n    print(\"   Next steps you should try:\")\n    print(\"    1) In the right-side Kaggle panel click '+ Add data' and ensure the dataset 'airline-passangers-booking-data' is added.\")\n    print(\"    2) Re-run the listing cell above and check the printed filenames for the exact survey CSV filename.\")\n    print(\"    3) If you see the correct file path from the listing, load it explicitly, e.g.:\")\n    print(\"         df_survey = pd.read_csv('/kaggle/input/your-folder/Survey_data_Inflight_Satisfaction_Score.csv')\")\n    print(\"    4) If the CSV has spaces in the name, use the exact filename (spaces matter).\")\nelse:\n    # Basic exploration (same as your explore_dataset function but inline)\n    print(\"\\n\" + \"=\"*60)\n    print(\"Survey Data - Quick Explore\")\n    print(\"=\"*60)\n    print(\"Shape:\", df_survey.shape)\n    print(\"\\nColumns and dtypes:\")\n    print(df_survey.dtypes)\n    print(\"\\nFirst 5 rows:\")\n    display(df_survey.head(5))\n    print(\"\\nMissing values (columns with >0 missing):\")\n    missing = df_survey.isnull().sum()\n    if missing.sum() > 0:\n        print(missing[missing > 0])\n    else:\n        print(\"No missing values detected\")\n    print(\"\\nDuplicate rows:\", df_survey.duplicated().sum())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:11.911446Z","iopub.execute_input":"2025-10-20T12:56:11.911750Z","iopub.status.idle":"2025-10-20T12:56:12.979126Z","shell.execute_reply.started":"2025-10-20T12:56:11.911722Z","shell.execute_reply":"2025-10-20T12:56:12.977943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full data-cleaning script (copy into one notebook cell or split as needed)\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Any, Optional, Tuple\n\n# -----------------------------\n# (Optional) LOAD DATASETS\n# -----------------------------\n# Uncomment & update paths if running locally / in Kaggle\n# df_reviews = pd.read_csv(\"/kaggle/input/.../AirlineScrappedReview.csv\")\n# df_comments = pd.read_csv(\"/kaggle/input/.../Customer_comment.csv\")\n# df_booking = pd.read_csv(\"/kaggle/input/.../Passanger_booking_data.csv\")\n# df_survey = pd.read_csv(\"/kaggle/input/.../Survey_data_Inflight_Satisfaction.csv\")\n\n# If you already have these DataFrame variables in the environment, keep them as is.\n# If not, they will be treated as None and skipped safely.\n\n# -----------------------------\n# Helpers & safe-copy\n# -----------------------------\ndef safe_copy(df: Optional[pd.DataFrame], name: str) -> Optional[pd.DataFrame]:\n    \"\"\"Return a copy if df is a DataFrame, otherwise print warning and return None.\"\"\"\n    if df is None:\n        print(f\"‚ö†Ô∏è  Warning: {name} is not loaded (None). Skipping.\")\n        return None\n    if not isinstance(df, pd.DataFrame):\n        print(f\"‚ö†Ô∏è  Warning: {name} is not a pandas DataFrame (type: {type(df)}). Skipping.\")\n        return None\n    print(f\"‚úì {name} loaded: shape {df.shape}\")\n    return df.copy()\n\ndef safe_mode(series: pd.Series, fallback: Any = \"Unknown\") -> Any:\n    \"\"\"Return the first mode or fallback if no mode exists.\"\"\"\n    modes = series.mode(dropna=True)\n    if modes.empty:\n        return fallback\n    return modes.iloc[0]\n\ndef fill_categorical(series: pd.Series, fallback: Any = \"Unknown\") -> pd.Series:\n    \"\"\"Fill categorical (object) series with mode or fallback.\"\"\"\n    try:\n        fill_val = safe_mode(series, fallback)\n        return series.fillna(fill_val)\n    except Exception:\n        return series.fillna(fallback)\n\ndef fill_numeric_with_median(series: pd.Series, fallback: float = 0.0) -> pd.Series:\n    \"\"\"Fill numeric series with median (fallback to 0 if median can't be computed).\"\"\"\n    try:\n        med = series.median(skipna=True)\n        if pd.isna(med):\n            med = fallback\n        return series.fillna(med)\n    except Exception:\n        return series.fillna(fallback)\n\ndef normalize_column_names(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Standardize column names: strip, replace spaces with underscore.\"\"\"\n    df = df.rename(columns=lambda c: str(c).strip().replace(' ', '_'))\n    return df\n\ndef trim_whitespace_in_object_cols(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Strip leading/trailing whitespace for string columns.\"\"\"\n    obj_cols = df.select_dtypes(include=['object', 'string']).columns\n    for c in obj_cols:\n        df[c] = df[c].astype(str).str.strip().replace({'nan': np.nan})\n    return df\n\n# -----------------------------\n# Create safe copies\n# -----------------------------\ndf_reviews_clean  = safe_copy(globals().get(\"df_reviews\"), \"AirlineScrappedReview\")\ndf_comments_clean = safe_copy(globals().get(\"df_comments\"), \"Customer_comment\")\ndf_booking_clean  = safe_copy(globals().get(\"df_booking\"), \"Passanger_booking_data\")\ndf_survey_clean   = safe_copy(globals().get(\"df_survey\"), \"Survey_data_Inflight_Satisfaction\")\n\nprint(\"\\nSetup complete. Proceeding to cleaning for loaded datasets.\\n\")\n\n# -----------------------------\n# Generic cleaning function\n# -----------------------------\ndef clean_dataframe(df: pd.DataFrame,\n                    name: str,\n                    fill_review_text: bool = False,\n                    review_text_col: str = \"Review_content\",\n                    review_title_col: str = \"Review_title\",\n                    drop_high_missing_pct: float = 50.0,\n                    auto_drop_high_missing: bool = False) -> Tuple[pd.DataFrame, dict]:\n    \"\"\"\n    General cleaning routine with documented decisions.\n    Returns cleaned df and a log dict of actions taken.\n    \"\"\"\n    log = {\"name\": name, \"original_shape\": df.shape, \"actions\": []}\n    \n    # Normalize column names + trim whitespace\n    df = normalize_column_names(df)\n    df = trim_whitespace_in_object_cols(df)\n    log[\"actions\"].append(\"Normalized column names and trimmed whitespace\")\n    \n    # Document missing value counts\n    missing_series = df.isnull().sum()\n    missing_info = missing_series[missing_series > 0].sort_values(ascending=False)\n    log[\"missing_before\"] = missing_info.to_dict()\n    if not missing_info.empty:\n        log[\"actions\"].append(f\"Found {len(missing_info)} columns with missing values\")\n    \n    # Decision: drop columns with > drop_high_missing_pct missing values (flag or drop)\n    cols_to_drop = []\n    total_rows = len(df)\n    for col, miss in missing_info.items():\n        pct = (miss / total_rows) * 100\n        if pct > drop_high_missing_pct:\n            cols_to_drop.append(col)\n    \n    if cols_to_drop:\n        if auto_drop_high_missing:\n            df.drop(columns=cols_to_drop, inplace=True)\n            log[\"actions\"].append(f\"Auto-dropped columns with >{drop_high_missing_pct}% missing: {cols_to_drop}\")\n        else:\n            log[\"actions\"].append(f\"Flagged columns with >{drop_high_missing_pct}% missing (not auto-dropped): {cols_to_drop}\")\n    \n    # Special case: fill review text/title placeholders if asked and columns exist\n    if fill_review_text:\n        if review_text_col in df.columns:\n            cnt = df[review_text_col].isnull().sum()\n            if cnt > 0:\n                df[review_text_col] = df[review_text_col].fillna(\"No review provided\")\n                log[\"actions\"].append(f\"Filled {cnt} missing '{review_text_col}' with 'No review provided'\")\n        if review_title_col in df.columns:\n            cnt = df[review_title_col].isnull().sum()\n            if cnt > 0:\n                df[review_title_col] = df[review_title_col].fillna(\"No title\")\n                log[\"actions\"].append(f\"Filled {cnt} missing '{review_title_col}' with 'No title'\")\n    \n    # Fill remaining missing values column-wise\n    for col in df.columns:\n        miss = df[col].isnull().sum()\n        if miss == 0:\n            continue\n        if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]):\n            fill_val = safe_mode(df[col], fallback=\"Unknown\")\n            df[col] = df[col].fillna(fill_val)\n            log[\"actions\"].append(f\"Filled {miss} missing in object column '{col}' with mode/fallback '{fill_val}'\")\n        elif pd.api.types.is_numeric_dtype(df[col]):\n            med = df[col].median(skipna=True)\n            if pd.isna(med):\n                med = 0.0\n            df[col] = df[col].fillna(med)\n            log[\"actions\"].append(f\"Filled {miss} missing in numeric column '{col}' with median {med}\")\n        else:\n            # For other dtypes (datetime, category, etc.)\n            if pd.api.types.is_datetime64_any_dtype(df[col]):\n                # Fill datetimes with forward fill then backward fill as fallback\n                df[col] = df[col].fillna(method='ffill').fillna(method='bfill')\n                df[col] = df[col].fillna(pd.NaT)\n                log[\"actions\"].append(f\"Attempted to fill datetime column '{col}' with ffill/bfill\")\n            else:\n                df[col] = df[col].fillna(\"Unknown\")\n                log[\"actions\"].append(f\"Filled {miss} missing in other column '{col}' with 'Unknown'\")\n    \n    # Remove exact duplicate rows\n    dup_before = df.duplicated().sum()\n    if dup_before > 0:\n        df.drop_duplicates(inplace=True)\n    dup_after = df.duplicated().sum()\n    log[\"actions\"].append(f\"Removed {dup_before - dup_after} duplicate rows (before: {dup_before})\")\n    \n    # Final shape and missing check\n    log[\"cleaned_shape\"] = df.shape\n    log[\"missing_after\"] = int(df.isnull().sum().sum())\n    log[\"rows_removed\"] = log[\"original_shape\"][0] - log[\"cleaned_shape\"][0]\n    \n    return df, log\n\n# -----------------------------\n# Run cleaning per dataset (only if loaded)\n# -----------------------------\nresults_logs = []\n\nif df_reviews_clean is not None:\n    df_reviews_clean, log_reviews = clean_dataframe(\n        df_reviews_clean,\n        name=\"AirlineScrappedReview\",\n        fill_review_text=True,\n        review_text_col=\"Review_content\",\n        review_title_col=\"Review_title\",\n        drop_high_missing_pct=50.0,\n        auto_drop_high_missing=False\n    )\n    results_logs.append(log_reviews)\n\nif df_comments_clean is not None:\n    df_comments_clean, log_comments = clean_dataframe(\n        df_comments_clean,\n        name=\"Customer_comment\",\n        fill_review_text=False,\n        drop_high_missing_pct=50.0,\n        auto_drop_high_missing=False\n    )\n    results_logs.append(log_comments)\n\nif df_booking_clean is not None:\n    df_booking_clean, log_booking = clean_dataframe(\n        df_booking_clean,\n        name=\"Passanger_booking_data\",\n        fill_review_text=False,\n        drop_high_missing_pct=50.0,\n        auto_drop_high_missing=False\n    )\n    results_logs.append(log_booking)\n\nif df_survey_clean is not None:\n    df_survey_clean, log_survey = clean_dataframe(\n        df_survey_clean,\n        name=\"Survey_data_Inflight_Satisfaction\",\n        fill_review_text=False,\n        drop_high_missing_pct=50.0,\n        auto_drop_high_missing=False\n    )\n    results_logs.append(log_survey)\n\n# -----------------------------\n# Summary report\n# -------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:12.980926Z","iopub.execute_input":"2025-10-20T12:56:12.981231Z","iopub.status.idle":"2025-10-20T12:56:14.236864Z","shell.execute_reply.started":"2025-10-20T12:56:12.981208Z","shell.execute_reply":"2025-10-20T12:56:14.235875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PART 3: SENTIMENT ANALYSIS\n# ============================================================================\n\n\"\"\"\nObjective: Add Sentiment_Analysis column to AirlineScrappedReview\nUsing: VADER (Valence Aware Dictionary and sEntiment Reasoner)\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SENTIMENT ANALYSIS\")\nprint(\"=\"*70)\n\n# Initialize VADER sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n\ndef get_sentiment_score(text):\n    \"\"\"\n    Apply VADER sentiment analysis to text\n    Returns compound score ranging from -1 (most negative) to +1 (most positive)\n    \"\"\"\n    if pd.isna(text) or text == \"No review provided\":\n        return 0.0  # Neutral for missing reviews\n    \n    scores = analyzer.polarity_scores(str(text))\n    return scores['compound']  # Compound score is the normalized score\n\ndef classify_sentiment(score):\n    \"\"\"\n    Classify sentiment based on compound score:\n    - Positive: score >= 0.05\n    - Negative: score <= -0.05\n    - Neutral: -0.05 < score < 0.05\n    \"\"\"\n    if score >= 0.05:\n        return 'Positive'\n    elif score <= -0.05:\n        return 'Negative'\n    else:\n        return 'Neutral'\n\n# Apply sentiment analysis to Review_content\nprint(\"\\nApplying VADER sentiment analysis to reviews...\")\ndf_reviews_clean['Sentiment_Score'] = df_reviews_clean['Review_content'].apply(get_sentiment_score)\ndf_reviews_clean['Sentiment_Analysis'] = df_reviews_clean['Sentiment_Score'].apply(classify_sentiment)\n\nprint(\"‚úì Sentiment analysis complete!\")\n\n# Display sentiment distribution\nprint(\"\\nSentiment Distribution:\")\nprint(df_reviews_clean['Sentiment_Analysis'].value_counts())\nprint(\"\\nSentiment Percentages:\")\nprint(df_reviews_clean['Sentiment_Analysis'].value_counts(normalize=True) * 100)\n\n# Visualize sentiment distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar plot\nsentiment_counts = df_reviews_clean['Sentiment_Analysis'].value_counts()\naxes[0].bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'gray', 'red'])\naxes[0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Sentiment')\naxes[0].set_ylabel('Count')\naxes[0].grid(axis='y', alpha=0.3)\n\n# Pie chart\naxes[1].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n            colors=['green', 'gray', 'red'], startangle=90)\naxes[1].set_title('Sentiment Proportion', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Relationship between Rating and Sentiment Score\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Scatter plot\naxes[0].scatter(df_reviews_clean['Rating'], df_reviews_clean['Sentiment_Score'], alpha=0.5)\naxes[0].set_title('Rating vs Sentiment Score', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Rating')\naxes[0].set_ylabel('Sentiment Score')\naxes[0].grid(alpha=0.3)\n\n# Box plot\ndf_reviews_clean.boxplot(column='Sentiment_Score', by='Rating', ax=axes[1])\naxes[1].set_title('Sentiment Score Distribution by Rating', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Rating')\naxes[1].set_ylabel('Sentiment Score')\nplt.suptitle('')\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# PART 4: DATA ENGINEERING QUESTIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATA ENGINEERING QUESTIONS\")\nprint(\"=\"*70)\n\n# ============================================================================\n# QUESTION 1: Top 10 Most Popular Flight Routes & Booking Distribution\n# ============================================================================\n\nprint(\"\\n--- Question 1: Flight Routes and Booking Distribution ---\")\n\n# Q1a: Top 10 most popular flight routes\nprint(\"\\nQ1a: What are the top 10 most popular flight routes?\")\n\n# Count routes from reviews dataset\nif 'Route' in df_reviews_clean.columns:\n    route_counts = df_reviews_clean['Route'].value_counts().head(10)\n    print(\"\\nTop 10 Most Popular Routes:\")\n    print(route_counts)\n    \n    # Visualize\n    plt.figure(figsize=(12, 6))\n    route_counts.plot(kind='barh', color='skyblue')\n    plt.title('Top 10 Most Popular Flight Routes', fontsize=14, fontweight='bold')\n    plt.xlabel('Number of Bookings/Reviews')\n    plt.ylabel('Route')\n    plt.gca().invert_yaxis()\n    plt.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# Q1b: Distribution of bookings across flight hours\nprint(\"\\nQ1b: What is the distribution of bookings across flight hours?\")\n\nif 'flight_hour' in df_booking_clean.columns:\n    # Plot distribution of flight hours\n    plt.figure(figsize=(12, 6))\n    \n    # Histogram\n    plt.subplot(1, 2, 1)\n    df_booking_clean['flight_hour'].hist(bins=24, color='coral', edgecolor='black')\n    plt.title('Distribution of Flight Hours', fontsize=14, fontweight='bold')\n    plt.xlabel('Flight Hour')\n    plt.ylabel('Number of Bookings')\n    plt.grid(axis='y', alpha=0.3)\n    \n    # Count plot\n    plt.subplot(1, 2, 2)\n    hour_counts = df_booking_clean['flight_hour'].value_counts().sort_index()\n    plt.plot(hour_counts.index, hour_counts.values, marker='o', linewidth=2, markersize=6)\n    plt.title('Bookings by Hour of Day', fontsize=14, fontweight='bold')\n    plt.xlabel('Hour (24h format)')\n    plt.ylabel('Number of Bookings')\n    plt.grid(alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Statistics\n    print(\"\\nFlight Hour Statistics:\")\n    print(f\"  Most popular hour: {df_booking_clean['flight_hour'].mode()[0]}\")\n    print(f\"  Average flight hour: {df_booking_clean['flight_hour'].mean():.2f}\")\n    print(f\"  Median flight hour: {df_booking_clean['flight_hour'].median()}\")\n\n# ============================================================================\n# QUESTION 2: Traveler Type & Class Rating Analysis\n# ============================================================================\n\nprint(\"\\n--- Question 2: Traveler Type & Class Ratings ---\")\nprint(\"\\nQ2: Which traveler type and class combination yields highest/lowest ratings?\")\n\n# Create pivot table\nif 'Traveller_type' in df_reviews_clean.columns and 'Class' in df_reviews_clean.columns:\n    traveler_class_ratings = df_reviews_clean.groupby(['Traveller_type', 'Class'])['Rating'].agg([\n        'mean', 'median', 'count'\n    ]).round(2)\n    \n    print(\"\\nAverage Ratings by Traveler Type and Class:\")\n    print(traveler_class_ratings)\n    \n    # Find highest and lowest\n    pivot_mean = df_reviews_clean.pivot_table(\n        values='Rating', \n        index='Traveller_type', \n        columns='Class', \n        aggfunc='mean'\n    )\n    \n    print(\"\\nPivot Table - Mean Ratings:\")\n    print(pivot_mean.round(2))\n    \n    # Heatmap\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(pivot_mean, annot=True, fmt='.2f', cmap='RdYlGn', center=5,\n                linewidths=1, linecolor='white', cbar_kws={'label': 'Average Rating'})\n    plt.title('Average Rating by Traveler Type and Class', fontsize=14, fontweight='bold')\n    plt.xlabel('Class')\n    plt.ylabel('Traveler Type')\n    plt.tight_layout()\n    plt.show()\n    \n    # Bar plot\n    fig, ax = plt.subplots(figsize=(12, 6))\n    df_reviews_clean.groupby(['Traveller_type', 'Class'])['Rating'].mean().unstack().plot(\n        kind='bar', ax=ax, rot=45\n    )\n    ax.set_title('Average Rating by Traveler Type and Class', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Traveler Type')\n    ax.set_ylabel('Average Rating')\n    ax.legend(title='Class', bbox_to_anchor=(1.05, 1))\n    ax.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    # Identify highest and lowest\n    max_rating = traveler_class_ratings['mean'].max()\n    min_rating = traveler_class_ratings['mean'].min()\n    max_combo = traveler_class_ratings[traveler_class_ratings['mean'] == max_rating].index[0]\n    min_combo = traveler_class_ratings[traveler_class_ratings['mean'] == min_rating].index[0]\n    \n    print(f\"\\n‚úì Highest Rating: {max_combo} with {max_rating:.2f}\")\n    print(f\"‚úì Lowest Rating: {min_combo} with {min_rating:.2f}\")\n\nprint(\"\\n‚úì Data engineering questions answered!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:14.237975Z","iopub.execute_input":"2025-10-20T12:56:14.238231Z","iopub.status.idle":"2025-10-20T12:56:27.426352Z","shell.execute_reply.started":"2025-10-20T12:56:14.238209Z","shell.execute_reply":"2025-10-20T12:56:27.425244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PART 4: FEATURE SELECTION & ENGINEERING\n# ============================================================================\n\n\"\"\"\nObjective: Select and engineer features for predicting passenger satisfaction\nTarget Variable: Binary classification based on Rating\n- Satisfied: Rating >= 5\n- Dissatisfied: Rating < 5\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FEATURE SELECTION & ENGINEERING\")\nprint(\"=\"*70)\n\n# ============================================================================\n# CREATE TARGET VARIABLE\n# ============================================================================\n\nprint(\"\\n--- Creating Target Variable ---\")\n\n# Create binary satisfaction label\ndf_reviews_clean['Satisfaction'] = (df_reviews_clean['Rating'] >= 5).astype(int)\n\n# Display distribution\nprint(\"\\nTarget Variable Distribution:\")\nprint(df_reviews_clean['Satisfaction'].value_counts())\nprint(\"\\nPercentages:\")\nprint(df_reviews_clean['Satisfaction'].value_counts(normalize=True) * 100)\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Count plot\ndf_reviews_clean['Satisfaction'].value_counts().plot(kind='bar', ax=axes[0], \n                                                      color=['red', 'green'])\naxes[0].set_title('Satisfaction Distribution', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Satisfaction (0=Dissatisfied, 1=Satisfied)')\naxes[0].set_ylabel('Count')\naxes[0].set_xticklabels(['Dissatisfied', 'Satisfied'], rotation=0)\naxes[0].grid(axis='y', alpha=0.3)\n\n# Pie chart\nsatisfaction_counts = df_reviews_clean['Satisfaction'].value_counts()\naxes[1].pie(satisfaction_counts.values, labels=['Dissatisfied', 'Satisfied'], \n            autopct='%1.1f%%', colors=['red', 'green'], startangle=90)\naxes[1].set_title('Satisfaction Proportion', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# FEATURE SELECTION - WITH JUSTIFICATION\n# ============================================================================\n\nprint(\"\\n--- Feature Selection ---\")\n\n\"\"\"\nSelected Features with Justification:\n\n1. Traveller_type: Different traveler types (Business, Leisure, etc.) may have \n   different satisfaction patterns and expectations.\n   \n2. Class: The cabin class (Economy, Business, First) is a strong indicator of \n   service level and passenger expectations.\n   \n3. Verified: Verified reviews may be more reliable and could correlate with \n   satisfaction patterns.\n   \n4. Sentiment_Score: Our calculated sentiment from review text provides direct \n   insight into passenger feelings.\n   \n5. Route: Some routes may consistently perform better/worse due to operational factors.\n\n6. Flying_Date features: Time-based patterns (day of week, month, season) can \n   affect satisfaction due to seasonal demand, weather, etc.\n\"\"\"\n\n# Select initial features\nselected_features = []\n\n# Feature 1: Traveller_type\nif 'Traveller_type' in df_reviews_clean.columns:\n    selected_features.append('Traveller_type')\n    print(\"\\n‚úì Feature: Traveller_type\")\n    print(\"  Justification: Different traveler types have different needs/expectations\")\n    \n    # Show relationship with target\n    plt.figure(figsize=(10, 5))\n    df_reviews_clean.groupby('Traveller_type')['Satisfaction'].mean().plot(kind='bar', \n                                                                             color='skyblue')\n    plt.title('Satisfaction Rate by Traveler Type', fontsize=14, fontweight='bold')\n    plt.xlabel('Traveler Type')\n    plt.ylabel('Satisfaction Rate')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# Feature 2: Class\nif 'Class' in df_reviews_clean.columns:\n    selected_features.append('Class')\n    print(\"\\n‚úì Feature: Class\")\n    print(\"  Justification: Service quality varies by cabin class\")\n    \n    plt.figure(figsize=(10, 5))\n    df_reviews_clean.groupby('Class')['Satisfaction'].mean().plot(kind='bar', \n                                                                   color='lightcoral')\n    plt.title('Satisfaction Rate by Class', fontsize=14, fontweight='bold')\n    plt.xlabel('Class')\n    plt.ylabel('Satisfaction Rate')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# Feature 3: Verified\nif 'Verified' in df_reviews_clean.columns:\n    selected_features.append('Verified')\n    print(\"\\n‚úì Feature: Verified\")\n    print(\"  Justification: Verification status may affect review authenticity\")\n    \n    plt.figure(figsize=(8, 5))\n    df_reviews_clean.groupby('Verified')['Satisfaction'].mean().plot(kind='bar', \n                                                                       color='lightgreen')\n    plt.title('Satisfaction Rate by Verification Status', fontsize=14, fontweight='bold')\n    plt.xlabel('Verified')\n    plt.ylabel('Satisfaction Rate')\n    plt.xticks(rotation=0)\n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# Feature 4: Sentiment_Score\nselected_features.append('Sentiment_Score')\nprint(\"\\n‚úì Feature: Sentiment_Score\")\nprint(\"  Justification: Direct measure of sentiment from review text\")\n\n# Scatter plot\nplt.figure(figsize=(10, 5))\nplt.scatter(df_reviews_clean['Sentiment_Score'], \n            df_reviews_clean['Satisfaction'], alpha=0.3)\nplt.title('Sentiment Score vs Satisfaction', fontsize=14, fontweight='bold')\nplt.xlabel('Sentiment Score')\nplt.ylabel('Satisfaction (0/1)')\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Distribution by satisfaction\nfig, ax = plt.subplots(figsize=(10, 5))\ndf_reviews_clean[df_reviews_clean['Satisfaction']==0]['Sentiment_Score'].hist(\n    bins=30, alpha=0.5, label='Dissatisfied', color='red', ax=ax)\ndf_reviews_clean[df_reviews_clean['Satisfaction']==1]['Sentiment_Score'].hist(\n    bins=30, alpha=0.5, label='Satisfied', color='green', ax=ax)\nax.set_title('Sentiment Score Distribution by Satisfaction', fontsize=14, fontweight='bold')\nax.set_xlabel('Sentiment Score')\nax.set_ylabel('Frequency')\nax.legend()\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Feature 5: Route (will be encoded)\nif 'Route' in df_reviews_clean.columns:\n    selected_features.append('Route')\n    print(\"\\n‚úì Feature: Route\")\n    print(\"  Justification: Route-specific operational factors affect satisfaction\")\n    \n    # Show top routes by satisfaction\n    route_satisfaction = df_reviews_clean.groupby('Route')['Satisfaction'].agg([\n        'mean', 'count'\n    ]).sort_values('mean', ascending=False)\n    \n    top_routes = route_satisfaction[route_satisfaction['count'] >= 10].head(10)\n    \n    plt.figure(figsize=(12, 6))\n    top_routes['mean'].plot(kind='barh', color='orange')\n    plt.title('Top 10 Routes by Satisfaction Rate (min 10 reviews)', \n              fontsize=14, fontweight='bold')\n    plt.xlabel('Satisfaction Rate')\n    plt.ylabel('Route')\n    plt.grid(axis='x', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# ============================================================================\n# FEATURE ENGINEERING - TIME-BASED FEATURES\n# ============================================================================\n\nprint(\"\\n--- Feature Engineering: Time-Based Features ---\")\n\nif 'Flying_Date' in df_reviews_clean.columns:\n    # Convert to datetime\n    df_reviews_clean['Flying_Date'] = pd.to_datetime(df_reviews_clean['Flying_Date'], \n                                                       errors='coerce')\n    \n    # Extract features\n    df_reviews_clean['Flight_Month'] = df_reviews_clean['Flying_Date'].dt.month\n    df_reviews_clean['Flight_DayOfWeek'] = df_reviews_clean['Flying_Date'].dt.dayofweek\n    df_reviews_clean['Flight_Quarter'] = df_reviews_clean['Flying_Date'].dt.quarter\n    \n    selected_features.extend(['Flight_Month', 'Flight_DayOfWeek', 'Flight_Quarter'])\n    \n    print(\"‚úì Engineered time-based features from Flying_Date\")\n    print(\"  - Flight_Month: Month of flight\")\n    print(\"  - Flight_DayOfWeek: Day of week (0=Monday, 6=Sunday)\")\n    print(\"  - Flight_Quarter: Quarter of year\")\n    \n    # Visualize effects\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # Month\n    df_reviews_clean.groupby('Flight_Month')['Satisfaction'].mean().plot(\n        kind='bar', ax=axes[0], color='skyblue')\n    axes[0].set_title('Satisfaction by Month', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Month')\n    axes[0].set_ylabel('Satisfaction Rate')\n    axes[0].grid(axis='y', alpha=0.3)\n    \n    # Day of Week\n    df_reviews_clean.groupby('Flight_DayOfWeek')['Satisfaction'].mean().plot(\n        kind='bar', ax=axes[1], color='lightcoral')\n    axes[1].set_title('Satisfaction by Day of Week', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Day of Week (0=Mon, 6=Sun)')\n    axes[1].set_ylabel('Satisfaction Rate')\n    axes[1].grid(axis='y', alpha=0.3)\n    \n    # Quarter\n    df_reviews_clean.groupby('Flight_Quarter')['Satisfaction'].mean().plot(\n        kind='bar', ax=axes[2], color='lightgreen')\n    axes[2].set_title('Satisfaction by Quarter', fontsize=12, fontweight='bold')\n    axes[2].set_xlabel('Quarter')\n    axes[2].set_ylabel('Satisfaction Rate')\n    axes[2].grid(axis='y', alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# ============================================================================\n# SUMMARY OF SELECTED FEATURES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SELECTED FEATURES SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\nTotal features selected:\", len(selected_features))\nprint(\"\\nFeature list:\")\nfor i, feature in enumerate(selected_features, 1):\n    print(f\"  {i}. {feature}\")\n\n# Check for missing values in selected features\nprint(\"\\nMissing values in selected features:\")\nfor feature in selected_features:\n    if feature in df_reviews_clean.columns:\n        missing = df_reviews_clean[feature].isnull().sum()\n        print(f\"  {feature}: {missing}\")\n\nprint(\"\\n‚úì Feature selection and engineering complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:27.427456Z","iopub.execute_input":"2025-10-20T12:56:27.427763Z","iopub.status.idle":"2025-10-20T12:56:31.063543Z","shell.execute_reply.started":"2025-10-20T12:56:27.427739Z","shell.execute_reply":"2025-10-20T12:56:31.062220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PART 5: DATA PREPROCESSING\n# ============================================================================\n\n\"\"\"\nPreprocessing Steps:\n1. Handle missing values in selected features\n2. Encode categorical variables\n3. Scale numerical features\n4. Test different preprocessing orders\n5. Split data into train/validation/test sets\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATA PREPROCESSING\")\nprint(\"=\"*70)\n\n# ============================================================================\n# PREPARE DATA FOR MODELING\n# ============================================================================\n\nprint(\"\\n--- Preparing Data ---\")\n\n# Create a copy for modeling\ndf_model = df_reviews_clean[selected_features + ['Satisfaction']].copy()\n\n# Remove any remaining missing values\nprint(f\"\\nRows before dropping missing values: {len(df_model)}\")\ndf_model.dropna(inplace=True)\nprint(f\"Rows after dropping missing values: {len(df_model)}\")\n\n# Separate features and target\nX = df_model[selected_features].copy()\ny = df_model['Satisfaction'].copy()\n\nprint(f\"\\nFeature matrix shape: {X.shape}\")\nprint(f\"Target vector shape: {y.shape}\")\nprint(f\"\\nClass distribution in target:\")\nprint(y.value_counts())\n\n# ============================================================================\n# ENCODING CATEGORICAL VARIABLES\n# ============================================================================\n\nprint(\"\\n--- Encoding Categorical Variables ---\")\n\n\"\"\"\nUnderstanding: Categorical variables need to be converted to numerical format\nNeed: Machine learning models require numerical input\nEffect: Creates numerical representations of categories\n\"\"\"\n\n# Identify categorical and numerical columns\ncategorical_cols = X.select_dtypes(include=['object']).columns.tolist()\nnumerical_cols = X.select_dtypes(include=['number']).columns.tolist()\n\nprint(f\"\\nCategorical features: {categorical_cols}\")\nprint(f\"Numerical features: {numerical_cols}\")\n\n# Store original distributions for comparison\noriginal_distributions = {}\nfor col in categorical_cols:\n    original_distributions[col] = X[col].value_counts()\n    print(f\"\\n{col} - Unique values: {X[col].nunique()}\")\n    print(X[col].value_counts().head())\n\n# Method 1: Label Encoding for ordinal features (if any)\n# Method 2: One-Hot Encoding for nominal features\n\n# For this dataset, we'll use Label Encoding for simplicity\n# In practice, you should choose based on feature nature\n\nX_encoded = X.copy()\nlabel_encoders = {}\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    X_encoded[col] = le.fit_transform(X[col].astype(str))\n    label_encoders[col] = le\n    \n    print(f\"\\n‚úì Encoded {col}:\")\n    print(f\"  Original categories: {len(le.classes_)}\")\n    print(f\"  Encoded range: 0 to {len(le.classes_)-1}\")\n    \n    # Visualize encoding effect\n    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n    \n    # Before encoding\n    X[col].value_counts().head(10).plot(kind='barh', ax=axes[0], color='skyblue')\n    axes[0].set_title(f'{col} - Before Encoding', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Count')\n    \n    # After encoding\n    X_encoded[col].value_counts().head(10).plot(kind='barh', ax=axes[1], color='lightcoral')\n    axes[1].set_title(f'{col} - After Encoding', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Count')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"\\n‚úì Categorical encoding complete!\")\n\n# ============================================================================\n# FEATURE SCALING\n# ============================================================================\n\nprint(\"\\n--- Feature Scaling ---\")\n\n\"\"\"\nUnderstanding: Features have different scales/ranges\nNeed: Ensures all features contribute equally to the model\nEffect: Transforms features to similar scales (typically mean=0, std=1)\n\"\"\"\n\n# Display original distributions\nprint(\"\\nOriginal feature statistics:\")\nprint(X_encoded.describe())\n\n# Visualize distributions before scaling\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\naxes = axes.ravel()\n\nfor i, col in enumerate(X_encoded.columns[:6]):\n    axes[i].hist(X_encoded[col], bins=30, color='skyblue', edgecolor='black')\n    axes[i].set_title(f'{col} - Before Scaling', fontsize=10)\n    axes[i].set_xlabel('Value')\n    axes[i].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Apply StandardScaler - FIT ON DATAFRAME, NOT SERIES\nscaler = StandardScaler()\nX_scaled_array = scaler.fit_transform(X_encoded)  # Returns numpy array\n\n# Convert back to DataFrame with same column names\nX_scaled = pd.DataFrame(X_scaled_array, columns=X_encoded.columns, index=X_encoded.index)\n\nprint(\"\\n‚úì Scaling applied using StandardScaler\")\nprint(f\"Number of features: {X_scaled.shape[1]}\")\nprint(f\"Feature names: {list(X_scaled.columns)}\")\nprint(\"\\nScaled feature statistics:\")\nprint(X_scaled.describe())\n\n# Visualize distributions after scaling\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\naxes = axes.ravel()\n\nfor i, col in enumerate(X_scaled.columns[:6]):\n    axes[i].hist(X_scaled[col], bins=30, color='lightcoral', edgecolor='black')\n    axes[i].set_title(f'{col} - After Scaling', fontsize=10)\n    axes[i].set_xlabel('Value')\n    axes[i].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# TESTING ORDER OF PREPROCESSING\n# ============================================================================\n\nprint(\"\\n--- Testing Preprocessing Order ---\")\n\n\"\"\"\nQuestion: Does the order of preprocessing steps matter?\nTest: Compare different orders and their effects\n\"\"\"\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n# Create a simple baseline model for testing\nbaseline_model = LogisticRegression(random_state=42, max_iter=1000)\n\n# Order 1: Encode ‚Üí Scale (what we did)\nX_order1 = X_scaled.copy()\nscores_order1 = cross_val_score(baseline_model, X_order1, y, cv=5, scoring='accuracy')\n\nprint(f\"\\nOrder 1 (Encode ‚Üí Scale):\")\nprint(f\"  Mean CV Accuracy: {scores_order1.mean():.4f} (+/- {scores_order1.std():.4f})\")\n\n# Order 2: Scale ‚Üí Encode (try on original with numerical only)\n# Note: Scaling categorical data doesn't make sense, so we'll test with only numerical\nif len(numerical_cols) > 0:\n    X_numerical_scaled = scaler.fit_transform(X[numerical_cols])\n    X_order2 = X_encoded.copy()\n    X_order2[numerical_cols] = X_numerical_scaled\n    \n    scores_order2 = cross_val_score(baseline_model, X_order2, y, cv=5, scoring='accuracy')\n    \n    print(f\"\\nOrder 2 (Scale numerical ‚Üí Encode categorical):\")\n    print(f\"  Mean CV Accuracy: {scores_order2.mean():.4f} (+/- {scores_order2.std():.4f})\")\n    \n    # Compare\n    print(f\"\\nDifference: {abs(scores_order1.mean() - scores_order2.mean()):.4f}\")\n    \n    if abs(scores_order1.mean() - scores_order2.mean()) < 0.01:\n        print(\"‚úì Order has minimal effect (< 1% difference)\")\n    else:\n        print(\"‚ö† Order matters! Choose the better performing one.\")\n\n# ============================================================================\n# TRAIN/VALIDATION/TEST SPLIT\n# ============================================================================\n\nprint(\"\\n--- Splitting Data ---\")\n\n\"\"\"\nSplit strategy: 70% train, 15% validation, 15% test\n\"\"\"\n\n# First split: 70% train, 30% temp\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n)\n\n# Second split: 15% validation, 15% test (50-50 split of temp)\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n)\n\nprint(f\"\\nTraining set: {X_train.shape} ({len(X_train)/len(X_scaled)*100:.1f}%)\")\nprint(f\"Validation set: {X_val.shape} ({len(X_val)/len(X_scaled)*100:.1f}%)\")\nprint(f\"Test set: {X_test.shape} ({len(X_test)/len(X_scaled)*100:.1f}%)\")\n\n# Check class distribution in each set\nprint(\"\\nClass distribution:\")\nprint(f\"  Train: {y_train.value_counts().values}\")\nprint(f\"  Val: {y_val.value_counts().values}\")\nprint(f\"  Test: {y_test.value_counts().values}\")\n\n# Visualize split\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nfor ax, (y_set, name) in zip(axes, [(y_train, 'Train'), (y_val, 'Validation'), (y_test, 'Test')]):\n    y_set.value_counts().plot(kind='bar', ax=ax, color=['red', 'green'])\n    ax.set_title(f'{name} Set Distribution', fontsize=12, fontweight='bold')\n    ax.set_xlabel('Satisfaction')\n    ax.set_ylabel('Count')\n    ax.set_xticklabels(['Dissatisfied', 'Satisfied'], rotation=0)\n    ax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n‚úì Data preprocessing complete!\")\nprint(\"\\n\" + \"=\"*70)\n\n# ============================================================================\n# SAVE PREPROCESSING INFORMATION FOR INFERENCE\n# ============================================================================\n\nprint(\"\\n--- Preprocessing Summary for Inference ---\")\nprint(f\"Total features after preprocessing: {X_scaled.shape[1]}\")\nprint(f\"Feature names: {list(X_scaled.columns)}\")\nprint(f\"Categorical columns (encoded): {categorical_cols}\")\nprint(f\"Numerical columns: {numerical_cols}\")\nprint(f\"Number of label encoders: {len(label_encoders)}\")\nprint(\"\\nLabel encoder mappings:\")\nfor col, encoder in label_encoders.items():\n    print(f\"  {col}: {len(encoder.classes_)} categories\")\n    print(f\"    Sample: {list(encoder.classes_[:3])} -> [0, 1, 2]\")\n\nprint(\"\\n\" + \"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:31.066300Z","iopub.execute_input":"2025-10-20T12:56:31.066800Z","iopub.status.idle":"2025-10-20T12:56:37.768698Z","shell.execute_reply.started":"2025-10-20T12:56:31.066775Z","shell.execute_reply":"2025-10-20T12:56:37.767477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PART 6: PREDICTIVE MODELING\n# ============================================================================\n\n\"\"\"\nObjective: Build and compare multiple models for passenger satisfaction prediction\nModels to compare:\n1. Baseline: Logistic Regression (Statistical ML)\n2. Random Forest (Statistical ML)\n3. Shallow Feed-Forward Neural Network (FFNN)\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PREDICTIVE MODELING\")\nprint(\"=\"*70)\n\n# Dictionary to store results\nmodel_results = {}\n\n# ============================================================================\n# MODEL 1: LOGISTIC REGRESSION (BASELINE)\n# ============================================================================\n\nprint(\"\\n--- Model 1: Logistic Regression (Baseline) ---\")\n\n\"\"\"\nHow it works: Linear model that uses logistic function to predict probability\n              of binary outcome. Simple, interpretable, fast.\n              \nLimitations: \n- Assumes linear relationship between features and log-odds\n- Cannot capture complex non-linear patterns\n- May underfit complex data\n\"\"\"\n\nprint(\"\\nTraining Logistic Regression...\")\n\n# Create and train model\nlr_model = LogisticRegression(random_state=42, max_iter=1000)\nlr_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_lr = lr_model.predict(X_train)\ny_val_pred_lr = lr_model.predict(X_val)\n\n# Calculate metrics\ndef calculate_metrics(y_true, y_pred, set_name):\n    \"\"\"Calculate and print classification metrics\"\"\"\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    \n    print(f\"\\n{set_name} Metrics:\")\n    print(f\"  Accuracy:  {acc:.4f}\")\n    print(f\"  Precision: {prec:.4f}\")\n    print(f\"  Recall:    {rec:.4f}\")\n    print(f\"  F1-Score:  {f1:.4f}\")\n    \n    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n\n# Training performance\nlr_train_metrics = calculate_metrics(y_train, y_train_pred_lr, \"Training\")\n\n# Validation performance\nlr_val_metrics = calculate_metrics(y_val, y_val_pred_lr, \"Validation\")\n\n# Store results\nmodel_results['Logistic Regression'] = {\n    'train': lr_train_metrics,\n    'val': lr_val_metrics,\n    'model': lr_model\n}\n\nprint(\"\\n‚úì Logistic Regression training complete!\")\n\n# ============================================================================\n# MODEL 2: RANDOM FOREST\n# ============================================================================\n\nprint(\"\\n--- Model 2: Random Forest ---\")\n\n\"\"\"\nHow it works: Ensemble of decision trees that vote on predictions.\n              Handles non-linear relationships and feature interactions.\n              \nLimitations:\n- Can overfit with too many/deep trees\n- Less interpretable than linear models\n- Slower training and prediction\n\"\"\"\n\nprint(\"\\nTraining Random Forest...\")\n\n# Create and train model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\nrf_model.fit(X_train, y_train)\n\n# Predictions\ny_train_pred_rf = rf_model.predict(X_train)\ny_val_pred_rf = rf_model.predict(X_val)\n\n# Training performance\nrf_train_metrics = calculate_metrics(y_train, y_train_pred_rf, \"Training\")\n\n# Validation performance\nrf_val_metrics = calculate_metrics(y_val, y_val_pred_rf, \"Validation\")\n\n# Store results\nmodel_results['Random Forest'] = {\n    'train': rf_train_metrics,\n    'val': rf_val_metrics,\n    'model': rf_model\n}\n\nprint(\"\\n‚úì Random Forest training complete!\")\n\n# ============================================================================\n# MODEL 3: SHALLOW FEED-FORWARD NEURAL NETWORK\n# ============================================================================\n\nprint(\"\\n--- Model 3: Shallow Feed-Forward Neural Network ---\")\n\n\"\"\"\nHow it works: Neural network with 1-2 hidden layers that learns non-linear\n              transformations through backpropagation.\n              \nLimitations:\n- Requires more data than traditional ML\n- Hyperparameter sensitive\n- Black-box nature (less interpretable)\n- Can overfit without regularization\n\"\"\"\n\nprint(\"\\nBuilding Neural Network architecture...\")\n\n# Build model\nnn_model = Sequential([\n    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dropout(0.3),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile model\nnn_model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"\\nModel Architecture:\")\nnn_model.summary()\n\n# Early stopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train model\nprint(\"\\nTraining Neural Network...\")\nhistory = nn_model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=100,\n    batch_size=32,\n    callbacks=[early_stop],\n    verbose=0\n)\n\nprint(f\"‚úì Training stopped at epoch {len(history.history['loss'])}\")\n\n# Predictions\ny_train_pred_nn = (nn_model.predict(X_train, verbose=0) > 0.5).astype(int).flatten()\ny_val_pred_nn = (nn_model.predict(X_val, verbose=0) > 0.5).astype(int).flatten()\n\n# Training performance\nnn_train_metrics = calculate_metrics(y_train, y_train_pred_nn, \"Training\")\n\n# Validation performance\nnn_val_metrics = calculate_metrics(y_val, y_val_pred_nn, \"Validation\")\n\n# Store results\nmodel_results['Neural Network'] = {\n    'train': nn_train_metrics,\n    'val': nn_val_metrics,\n    'model': nn_model,\n    'history': history\n}\n\nprint(\"\\n‚úì Neural Network training complete!\")\n\n# ============================================================================\n# PLOT TRAINING HISTORY (NEURAL NETWORK)\n# ============================================================================\n\nprint(\"\\n--- Neural Network Training History ---\")\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Loss\naxes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\naxes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\naxes[0].set_title('Model Loss During Training', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# Accuracy\naxes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\naxes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\naxes[1].set_title('Model Accuracy During Training', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].legend()\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# COMPARE ALL MODELS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL COMPARISON\")\nprint(\"=\"*70)\n\n# Create comparison dataframe\ncomparison_data = []\nfor model_name, results in model_results.items():\n    comparison_data.append({\n        'Model': model_name,\n        'Train_Acc': results['train']['accuracy'],\n        'Val_Acc': results['val']['accuracy'],\n        'Train_F1': results['train']['f1'],\n        'Val_F1': results['val']['f1'],\n        'Overfit': results['train']['accuracy'] - results['val']['accuracy']\n    })\n\ncomparison_df = pd.DataFrame(comparison_data)\nprint(\"\\n\", comparison_df.to_string(index=False))\n\n# Visualize comparison\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Accuracy comparison\nax = axes[0, 0]\nx = np.arange(len(comparison_df))\nwidth = 0.35\nax.bar(x - width/2, comparison_df['Train_Acc'], width, label='Train', color='skyblue')\nax.bar(x + width/2, comparison_df['Val_Acc'], width, label='Validation', color='lightcoral')\nax.set_title('Accuracy Comparison', fontsize=12, fontweight='bold')\nax.set_ylabel('Accuracy')\nax.set_xticks(x)\nax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\n# F1-Score comparison\nax = axes[0, 1]\nax.bar(x - width/2, comparison_df['Train_F1'], width, label='Train', color='lightgreen')\nax.bar(x + width/2, comparison_df['Val_F1'], width, label='Validation', color='orange')\nax.set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\nax.set_ylabel('F1-Score')\nax.set_xticks(x)\nax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\n# Overfitting comparison\nax = axes[1, 0]\nax.bar(comparison_df['Model'], comparison_df['Overfit'], color='purple')\nax.set_title('Overfitting (Train - Val Accuracy)', fontsize=12, fontweight='bold')\nax.set_ylabel('Difference')\nax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\nax.axhline(y=0, color='red', linestyle='--', linewidth=1)\nax.grid(axis='y', alpha=0.3)\n\n# All metrics comparison\nax = axes[1, 1]\nmetrics_to_plot = ['Train_Acc', 'Val_Acc', 'Train_F1', 'Val_F1']\ncomparison_df[metrics_to_plot].plot(kind='bar', ax=ax, rot=0)\nax.set_title('All Metrics Overview', fontsize=12, fontweight='bold')\nax.set_ylabel('Score')\nax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right')\nax.legend(['Train Acc', 'Val Acc', 'Train F1', 'Val F1'])\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Select best model based on validation F1-score\nbest_model_name = comparison_df.loc[comparison_df['Val_F1'].idxmax(), 'Model']\nprint(f\"\\n‚úì Best performing model: {best_model_name}\")\nprint(f\"  Validation F1-Score: {comparison_df.loc[comparison_df['Val_F1'].idxmax(), 'Val_F1']:.4f}\")\n\n# ============================================================================\n# TEST SET EVALUATION (BEST MODEL)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TEST SET EVALUATION\")\nprint(\"=\"*70)\n\nprint(f\"\\nEvaluating {best_model_name} on unseen test data...\")\n\n# Get best model\nbest_model = model_results[best_model_name]['model']\n\n# Predict on test set\nif best_model_name == 'Neural Network':\n    y_test_pred = (best_model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\nelse:\n    y_test_pred = best_model.predict(X_test)\n\n# Calculate test metrics\ntest_metrics = calculate_metrics(y_test, y_test_pred, \"Test Set\")\n\n# Detailed classification report\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(y_test, y_test_pred, \n                          target_names=['Dissatisfied', 'Satisfied']))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_test_pred)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Confusion Matrix - counts\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n            xticklabels=['Dissatisfied', 'Satisfied'],\n            yticklabels=['Dissatisfied', 'Satisfied'])\naxes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\n\n# Confusion Matrix - percentages\ncm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\nsns.heatmap(cm_percent, annot=True, fmt='.2f', cmap='Blues', ax=axes[1],\n            xticklabels=['Dissatisfied', 'Satisfied'],\n            yticklabels=['Dissatisfied', 'Satisfied'])\naxes[1].set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold')\naxes[1].set_ylabel('True Label')\naxes[1].set_xlabel('Predicted Label')\n\nplt.tight_layout()\nplt.show()\n\n# ROC Curve\nif best_model_name == 'Neural Network':\n    y_test_proba = best_model.predict(X_test, verbose=0).flatten()\nelse:\n    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title(f'ROC Curve - {best_model_name}', fontsize=14, fontweight='bold')\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n‚úì Test set evaluation complete!\")\nprint(f\"  Test Accuracy: {test_metrics['accuracy']:.4f}\")\nprint(f\"  Test F1-Score: {test_metrics['f1']:.4f}\")\nprint(f\"  ROC AUC: {roc_auc:.4f}\")\n\nprint(\"\\n\" + \"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:56:37.770087Z","iopub.execute_input":"2025-10-20T12:56:37.770464Z","iopub.status.idle":"2025-10-20T12:57:15.373115Z","shell.execute_reply.started":"2025-10-20T12:56:37.770432Z","shell.execute_reply":"2025-10-20T12:57:15.372098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# --- MOCK SETUP (replace with your real objects) ---\n# X_train is the training DataFrame used for model training\n# scaler is the fitted scaler\n# best_model is your trained model\n# label_encoders is a dict of fitted LabelEncoders for categorical columns\n# categorical_cols is a list of categorical column names used in training\n\n# For demonstration, we create dummy objects\nX_train = pd.DataFrame({\n    'Traveller_type_enc': [0,1,2],\n    'Class_enc': [0,1,2],\n    'Verified': [0,1,1],\n    'Sentiment_Score': [0.0, 0.5, -0.5],\n    'Route_enc': [0,1,2],\n    'Flight_Month': [1,6,12],\n    'Flight_DayOfWeek': [0,3,6],\n    'Flight_Quarter': [1,2,4]\n})\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nscaler = StandardScaler()\nscaler.fit(X_train)\n\n# Dummy LabelEncoders\ncategorical_cols = ['Traveller_type', 'Class', 'Route']\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    le.fit(['Business', 'Solo Leisure', 'Economy', 'London to New York', 'Paris to Rome'])\n    label_encoders[col] = le\n\n# Dummy best model (replace with your trained model)\nfrom sklearn.linear_model import LogisticRegression\nbest_model = LogisticRegression()\nbest_model.fit(X_train, [1,0,1])  # just dummy fit\nbest_model_name = 'Logistic Regression'\n\n# --- PREDICTION FUNCTION ---\ndef predict_passenger_satisfaction(traveller_type, travel_class, verified,\n                                   review_text, route, flying_date):\n    \n    # Sentiment\n    sentiment_score = 0.8 if 'excellent' in review_text.lower() else -0.8\n    sentiment_label = \"Positive\" if sentiment_score>0 else \"Negative\"\n    \n    verified_int = int(bool(verified))\n    \n    # Encode categorical\n    input_dict = {\n        'Traveller_type': traveller_type,\n        'Class': travel_class,\n        'Verified': verified_int,\n        'Sentiment_Score': sentiment_score,\n        'Route': route,\n        'Flight_Month': pd.to_datetime(flying_date).month,\n        'Flight_DayOfWeek': pd.to_datetime(flying_date).dayofweek,\n        'Flight_Quarter': pd.to_datetime(flying_date).quarter\n    }\n    input_df = pd.DataFrame([input_dict])\n    \n    # Encode categories\n    for col in categorical_cols:\n        val = str(input_df[col].values[0])\n        if val in label_encoders[col].classes_:\n            input_df[col] = label_encoders[col].transform([val])[0]\n        else:\n            input_df[col] = -1\n    \n    # Reindex to match training columns\n    col_mapping = {\n        'Traveller_type': 'Traveller_type_enc',\n        'Class': 'Class_enc',\n        'Route': 'Route_enc'\n    }\n    input_df = input_df.rename(columns=col_mapping)\n    input_df = input_df[X_train.columns]  # reorder\n    \n    # Scale\n    input_scaled = scaler.transform(input_df)\n    \n    # Predict\n    if best_model_name == 'Neural Network':\n        pred_proba = best_model.predict(input_scaled)[0]  # dummy\n    else:\n        pred_proba = best_model.predict_proba(input_scaled)[0][1]\n    pred_label = int(pred_proba > 0.5)\n    \n    satisfaction_label = \"Satisfied\" if pred_label==1 else \"Dissatisfied\"\n    confidence_pct = pred_proba*100 if pred_label==1 else (1-pred_proba)*100\n    \n    return {\n        'prediction': satisfaction_label,\n        'confidence': confidence_pct,\n        'sentiment': sentiment_label,\n        'sentiment_score': sentiment_score\n    }\n\n# --- TEST ---\nexamples = [\n    {'traveller_type':'Business','travel_class':'Business','verified':True,\n     'review_text':'Excellent flight','route':'London to New York','flying_date':'2024-06-15'},\n    {'traveller_type':'Solo Leisure','travel_class':'Economy','verified':True,\n     'review_text':'Terrible service','route':'Paris to Rome','flying_date':'2024-08-20'}\n]\n\nfor ex in examples:\n    result = predict_passenger_satisfaction(\n        traveller_type=ex['traveller_type'],\n        travel_class=ex['travel_class'],\n        verified=ex['verified'],\n        review_text=ex['review_text'],\n        route=ex['route'],\n        flying_date=ex['flying_date']\n    )\n    print(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:57:15.374366Z","iopub.execute_input":"2025-10-20T12:57:15.374749Z","iopub.status.idle":"2025-10-20T12:57:15.420989Z","shell.execute_reply.started":"2025-10-20T12:57:15.374719Z","shell.execute_reply":"2025-10-20T12:57:15.418954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# PART 8: EXPLAINABLE AI (XAI) - FIXED\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"EXPLAINABLE AI (XAI)\")\nprint(\"=\"*70)\n\n# ============================================================================\n# 1. PREPARE TEST SET\n# ============================================================================\n\nX_test_encoded = X_test.copy()\n\n# --- Encode categorical variables (map unseen labels to -1) ---\ncategorical_cols = ['Traveller_type', 'Class', 'Route', 'Verified']  # adjust as in training\n\nfor col in categorical_cols:\n    if col in label_encoders:\n        le = label_encoders[col]\n        X_test_encoded[col + '_enc'] = X_test_encoded[col].map(\n            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n        )\n    else:\n        print(f\"Warning: LabelEncoder for {col} not found!\")\n\n# Drop original categorical columns\nX_test_encoded.drop(columns=categorical_cols, inplace=True, errors='ignore')\n\n# --- Feature engineering for datetime ---\nif 'Flying_Date' in X_test_encoded.columns:\n    X_test_encoded['Flying_Date'] = pd.to_datetime(X_test_encoded['Flying_Date'])\n    X_test_encoded['Flight_Month'] = X_test_encoded['Flying_Date'].dt.month\n    X_test_encoded['Flight_DayOfWeek'] = X_test_encoded['Flying_Date'].dt.dayofweek\n    X_test_encoded['Flight_Quarter'] = X_test_encoded['Flying_Date'].dt.quarter\n    X_test_encoded.drop(columns=['Flying_Date'], inplace=True)\n\n# Ensure all columns match training set\nmissing_cols = set(X_train.columns) - set(X_test_encoded.columns)\nfor col in missing_cols:\n    X_test_encoded[col] = 0  # fill missing engineered columns with 0\n\nX_test_encoded = X_test_encoded[X_train.columns]\n\n# ============================================================================\n# 2. SHAP EXPLAINER\n# ============================================================================\n\nprint(\"\\n--- Global Explanation: SHAP ---\")\n\nimport shap\n\nif best_model_name == 'Random Forest':\n    explainer = shap.TreeExplainer(best_model)\n    shap_values = explainer.shap_values(X_test_encoded)\n    if isinstance(shap_values, list):\n        shap_values = shap_values[1]  # binary class 1\n\nelif best_model_name == 'Logistic Regression':\n    explainer = shap.LinearExplainer(best_model, X_train, feature_dependence=\"independent\")\n    shap_values = explainer.shap_values(X_test_encoded)\n\nelse:  # Neural Network\n    background = shap.sample(X_train, 100)\n    def model_predict(data):\n        return best_model.predict(data, verbose=0).flatten()\n    explainer = shap.KernelExplainer(model_predict, background)\n    shap_values = explainer.shap_values(X_test_encoded[:100])\n\nprint(\"‚úì SHAP values calculated!\")\n\n# ============================================================================\n# 3. SHAP VISUALIZATIONS\n# ============================================================================\n\nplt.figure(figsize=(10, 8))\nshap.summary_plot(shap_values, X_test_encoded, plot_type=\"bar\", show=False)\nplt.title('Global Feature Importance (SHAP)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10, 8))\nshap.summary_plot(shap_values, X_test_encoded, show=False)\nplt.title('Feature Effects on Model Output (SHAP)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# Top features as DataFrame\nfeature_importance = pd.DataFrame({\n    'Feature': X_test_encoded.columns,\n    'Importance': np.abs(shap_values).mean(axis=0)\n}).sort_values('Importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features (SHAP):\")\nprint(feature_importance.head(10).to_string(index=False))\n\nplt.figure(figsize=(10, 6))\ntop_features = feature_importance.head(10)\nplt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\nplt.yticks(range(len(top_features)), top_features['Feature'])\nplt.xlabel('Mean |SHAP Value|')\nplt.title('Top 10 Features by SHAP Importance')\nplt.gca().invert_yaxis()\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# 4. LOCAL EXPLANATION WITH LIME\n# ============================================================================\n\nimport lime\nimport lime.lime_tabular\n\nlime_explainer = lime.lime_tabular.LimeTabularExplainer(\n    X_train.values,\n    feature_names=X_train.columns.tolist(),\n    class_names=['Dissatisfied', 'Satisfied'],\n    mode='classification',\n    random_state=42\n)\n\nif best_model_name == 'Neural Network':\n    def predict_fn(X):\n        proba = best_model.predict(X, verbose=0)\n        return np.hstack([1 - proba, proba])\nelse:\n    def predict_fn(X):\n        return best_model.predict_proba(X)\n\nlime_samples = [0, 10, 20]\nfor idx in lime_samples:\n    lime_exp = lime_explainer.explain_instance(\n        X_test_encoded.iloc[idx].values,\n        predict_fn,\n        num_features=10\n    )\n    true_label = 'Satisfied' if y_test.iloc[idx] == 1 else 'Dissatisfied'\n    pred_proba = predict_fn(X_test_encoded.iloc[idx:idx+1].values)[0]\n    pred_label = 'Satisfied' if pred_proba[1] > 0.5 else 'Dissatisfied'\n\n    print(f\"\\nSample {idx}: True={true_label}, Predicted={pred_label}, Prob={pred_proba[1]:.3f}\")\n    fig = lime_exp.as_pyplot_figure()\n    plt.title(f'LIME Explanation - Sample {idx}\\nPrediction: {pred_label}')\n    plt.tight_layout()\n    plt.show()\n    print(\"Top features:\")\n    for feature, weight in lime_exp.as_list()[:5]:\n        print(f\"  {feature}: {weight:.4f}\")\n\nprint(\"\\n‚úì XAI analysis complete!\")\nprint(\"\\n\" + \"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:06:00.405977Z","iopub.execute_input":"2025-10-20T13:06:00.406361Z","iopub.status.idle":"2025-10-20T13:06:01.930414Z","shell.execute_reply.started":"2025-10-20T13:06:00.406334Z","shell.execute_reply":"2025-10-20T13:06:01.929492Z"}},"outputs":[],"execution_count":null}]}